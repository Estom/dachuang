# 数据分析的思路和规划
> 做数据分析第一件最重要的事情就是数据来源。关于数据来源的思考有两方面：
通过个人网站记录用户的数据，这种方式很不靠谱，因为由于网站本身不具有太多
内容，也没有完整的合理的数据采集方式，很难对数据进行整理。

## 对当前数据库进行分析

-----

**用户和文章关联的表有哪些**


* 用户 历史记录 文章
* 用户 推荐     文章
* 用户 关注     公众号   推送文章
* 用户 喜欢     文章
* 用户 浏览     文章
* 用户 浏览     标签     关联文章

**数据来源说明**

* 从文章角度寻找数据来源：  
    文章 - 浏览量 - 喜欢数量 - 公众号。给出一份文章和公众号的公开数据。

* 从用户角度寻找数据来源  
    用户 - 关注的类型，浏览的类型等等，给出一份用户个人报告。

**平台中的实体**  
* 文章  标签  发布者  用户 类别

**平台中存在的关联关系**  
* 用户   浏览  喜欢  历史  推荐 关注
* 发布者  发布
* 标签   标记

-------
## 数据分析类型：

>所有的实体类都可以形成排行榜，所有的关联类都可以形成分布图。

**实体分析**

* 用户分析
* 图文分析
* 发布者分析
* 标签分析

**关联分析**
> 其实如果数据足够多的话，的确可以实现很多平行分析，交叉分析之类的。
现在应该考虑的就是在数据受限的情况下应该采取的分析策略。
* 用户-发布者
* 用户-文章
* 用户-标签
* 发布者-文章
* 发布者-标签

**时间变化**

* 静态数据分析  
  数据的分布_比例分布（饼图），数量分布（柱状图）
* 动态数据分析  
  数据的变化_同比增长，环比增长


> 当下不需要考虑时间变化引起的数据变化。


----------
## 具体分析说明

> 应当都以周榜的形式

**实体分析-用户分析**  

用户分析应该是用户自己可见的内容，每个用户都会有自己的数据。  

阅读统计：需要一张用户-阅读-文章的表格。统计用户阅读文章的数量

点赞统计：需要一张用户-点赞-文章的表格。统计用户喜欢文章的数量

*用户偏好分析:通过用户的阅读内容、点赞内容、阅读标签、关注内容生成一段对用户个性描述的语言。觉得这个可能
没有必要，如果最后还有时间的话就去实现。*

**实体分析-图文分析**  

文章排行榜：统计每篇文章被点赞和被浏览的次数，生成排行数据，标题和热度

**实体分析-发布者分析**  

发布者热度排行榜：统计发布者发布的文章被点赞、浏览的数量生成新的排行数据，名称和热度

发布者被关注排行：统计发布者被关注的排行榜。

**实体分析-标签分析**  

标签数据排行榜：通过热词分析的结果，使用竖排统计图进行呈现，词汇和数量

-----标签热度排行：用户浏览和用户点赞的标签的排行，标签热度。觉得这个没有标有
因为一个标签出现的多，必然受到关注的也越多。


**关联分析-类别分布**

不同分类下文章的数量分布（饼状图，名称和百分比

用户对不同分类的文章的阅读分布（饼状图，名称和百分比

**关联分析-平台来源分析**

不同来源发布文章的数量分布（饼状图，名称和百分比）

用户对不同来源的文章的阅读分布（饼状图，名称和百分比）



**时间变化**

> 这个等到以后有时间进行扩展

**微信版块**
> 因为网络总有些数据库给出了微信的数据的分析权威结果，所以，可以链接到
网络中提供的数据接口，在平台中，提供西工大微信数据排行的权威数据。一会
了解一下这一部分的内容，如果这一部分简单，可以先实现这一部分。

## 开发流程说明

1. 完善数据库中的数据格式，根据当前的要求，对数据库进行修改，并对一些基本逻辑
进行改进，因为有一些新的数据需求。（这一部分应该是主要修改网络中的数据逻辑内容的）
把点赞和浏览量的内容写的更加合理，还有其他的一些事情。

2. 实现对数据库的基本操作，因为这一部分涉及大量的取数据操作，所以需要单独处理
取数据的过程（包括关联取数据等），然后才能进行统计和分析。

3. 完成分析逻辑，并且将数据保存成XML格式，因为数据形式比较多样，但是每一种数据的
条数又非常少，所以以XML文件的格式，保存数据比存到数据库要简单高效的多。但是需要
学习python对XML的操作。

4. 对数据进行可视化。以最近流行的数据报告的形式呈现，主要使用H5全屏页面的格式。
最后的时候对整个过程进行完善，添加时间范围为一周，并且每次运行清空部分数据表格。

> 说实话，我觉得这个数据分析交给一个人做可能就需要完整一周的时间，不过现在
也没有什么办法了，硬着头皮上呗。最近还有很多其他的事情也都需要处理，要注意
时间上的协调。

### 头脑风暴了一下
* 历史记录本来就已经实现了，也就是说浏览量和喜欢的逻辑应该差不多，那么对于数据
重做的可能就只有这一部分。对于关注、浏览、喜欢这三个动作真的很像，都是由用户发
发起的关联表。有空得详细绘制一下整个数据库的逻辑图了。

* 对于第二部分，对数据库的封装，想了半天，觉得比较麻烦，应该是可以直接通过
Django对数据库的封装来实现对数据的操作，但是存在的问题是，每次请求都要重新
获取数据，而不是使用一个静态的文件，会导致这个过程很慢。所以我觉得Django应该
提供了一种方法，可以让我们动态获取到的数据静态化。首先查找一下，然后再进行
实际操作，尽量使用Django内部的方法。我觉得这样会节省大量的时间，（毕竟自己专门写数据库的基础查询和关联
查询的封装最少也得一天）。

* 关于微信公众号接口的调用，需要阅读一点资料和使用说明书了，这一部分肯定不能
通过Django自己实现了，所以只能通过URL直接访问别人提供的数据接口，这一部分要写
到Analysis部分（如果自己要封装对基础数据库的操作，也要写到这一部分）

* 最后关于数据的呈现和路由问题，决定在Django里边新开一个文件专门用来显示date页面
首先完成xml格式的数据输出，或者每写一部分就订立数据标准。

* 卧槽，刚才灵感乍现了一下，，，，对染每次数据库操作会浪费时间，但我可以通过路由
决定每一周调用一次访问数据库生成新的数据内容，而不是每次访问这个路由都是这样。
那么现在的问题就是Django如何把生成的动态页面静态化！！！！这应该是一个非常简单的
任务吧。

* 卧槽，贼开心，贼激动，说有真踏吗就有，真的就爱上Django了。上次那个标签的内部
循环语句，简洁到让我无话可说，这次，五体投地了，献上小弟的膝盖。果然牛逼，以后
有钱了，我天天捐社区好吧。

* 又加深了解了一下，这个东西不仅仅可以通过生成静态页面来实现，也可以通过缓存机制
来达到更高效更简单的管理。所以，这里的访问数据库数量过大造成的问题就不存在了。而且
小白的那个执行那么多数据库查询的方法，也就不会存在效率问题，只要将缓存的间隔
设置成每周更新一次应该就会解决问题，那么现在，关注点应该集中在实现逻辑上边了。
暂时也不用考虑静态页面的事情，可以直接输出。

* 那么在这个基础上，就应该让用户的个人数据统计独立到用户的个人页面。

* 逻辑说明：点击一篇文章，添加或更新一次浏览记录，并将浏览数量增加一次，在显示的时候
直接访问文章属性的浏览数量。
点击一次喜欢，添加或更新一次喜欢记录，并将喜欢数量增加一次，在显示数量的时候直接
访问文章的属性的喜欢数量。
已经完成了这一部分，逻辑和数据都已经实现了，现在应该按照计划对相关表格进行操作。

* 已经完成了Android界面的数据传递，检查出了几个bug，浪费了整整一天时间。
有大量的数据库操作，所以运行效率极低，可能需要一份多重才能查询完成数据，
然后渲染估计又要三十秒。但这都不是问题。但愿Django的生成静态页面或者Django
的服务器缓存功能能够解决这个问题。

* 考虑数据界面的呈现。贼开心，发现了一个炒鸡牛逼的库，chart.js，应该可以完全满足
自己的需求。应该根据一下步骤来完成任务：
制定每个页面的显示方式。
    * 第一组文章热度和标签排行，使用竖排框
    * 第二组发布者使用横排的柱状图
    * 第三组类别表使用饼图
    * 第四组来源表使用环状图
选择可行的图，进行调试，规范化数据，排版。

* 哎，又遇到一个知识盲区，js固然强大，然而……就是不会，我也很绝望。
现在先配置一下这个组件提供的chartJs吧，如果以后要改好，肯定还需要从JS的基础
知识开始学习。

