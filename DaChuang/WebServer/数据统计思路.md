# 数据分析的思路和规划
> 做数据分析第一件最重要的事情就是数据来源。关于数据来源的思考有两方面：
通过个人网站记录用户的数据，这种方式很不靠谱，因为由于网站本身不具有太多
内容，也没有完整的合理的数据采集方式，很难对数据进行整理。

## 对当前数据库进行分析

-----

**用户和文章关联的表有哪些**


* 用户 历史记录 文章
* 用户 推荐     文章
* 用户 关注     公众号   推送文章
* 用户 喜欢     文章
* 用户 浏览     文章
* 用户 浏览     标签     关联文章

**数据来源说明**

* 从文章角度寻找数据来源：  
    文章 - 浏览量 - 喜欢数量 - 公众号。给出一份文章和公众号的公开数据。

* 从用户角度寻找数据来源  
    用户 - 关注的类型，浏览的类型等等，给出一份用户个人报告。

**平台中的实体**  
* 文章  标签  发布者  用户 类别

**平台中存在的关联关系**  
* 用户   浏览  喜欢  历史  推荐 关注
* 发布者  发布
* 标签   标记

-------
## 数据分析类型：

>所有的实体类都可以形成排行榜，所有的关联类都可以形成分布图。

**实体分析**

* 用户分析
* 图文分析
* 发布者分析
* 标签分析

**关联分析**
> 其实如果数据足够多的话，的确可以实现很多平行分析，交叉分析之类的。
现在应该考虑的就是在数据受限的情况下应该采取的分析策略。
* 用户-发布者
* 用户-文章
* 用户-标签
* 发布者-文章
* 发布者-标签

**时间变化**

* 静态数据分析  
  数据的分布_比例分布（饼图），数量分布（柱状图）
* 动态数据分析  
  数据的变化_同比增长，环比增长


> 当下不需要考虑时间变化引起的数据变化。


----------
## 具体分析说明

> 应当都以周榜的形式

**实体分析-用户分析**  

用户分析应该是用户自己可见的内容，每个用户都会有自己的数据。  

阅读统计：需要一张用户-阅读-文章的表格。统计用户阅读文章的数量

点赞统计：需要一张用户-点赞-文章的表格。统计用户喜欢文章的数量

*用户偏好分析:通过用户的阅读内容、点赞内容、阅读标签、关注内容生成一段对用户个性描述的语言。觉得这个可能
没有必要，如果最后还有时间的话就去实现。*

**实体分析-图文分析**  

文章排行榜：统计每篇文章被点赞和被浏览的次数，生成排行数据，标题和热度

**实体分析-发布者分析**  

发布者热度排行榜：统计发布者发布的文章被点赞、浏览的数量生成新的排行数据，名称和热度

发布者被关注排行：统计发布者被关注的排行榜。

**实体分析-标签分析**  

标签数据排行榜：通过热词分析的结果，使用竖排统计图进行呈现，词汇和数量

标签热度排行：用户浏览和用户点赞的标签的排行，标签热度


**关联分析-类别分布**

不同分类下文章的数量分布（饼状图，名称和百分比

用户对不同分类的文章的阅读分布（饼状图，名称和百分比

**关联分析-平台来源分析**

不同来源发布文章的数量分布（饼状图，名称和百分比）

用户对不同来源的文章的阅读分布（饼状图，名称和百分比）



**时间变化**

> 这个等到以后有时间进行扩展

**微信版块**
> 因为网络总有些数据库给出了微信的数据的分析权威结果，所以，可以链接到
网络中提供的数据接口，在平台中，提供西工大微信数据排行的权威数据。一会
了解一下这一部分的内容，如果这一部分简单，可以先实现这一部分。

## 开发流程说明

1. 完善数据库中的数据格式，根据当前的要求，对数据库进行修改，并对一些基本逻辑
进行改进，因为有一些新的数据需求。（这一部分应该是主要修改网络中的数据逻辑内容的）
把点赞和浏览量的内容写的更加合理，还有其他的一些事情。

2. 实现对数据库的基本操作，因为这一部分涉及大量的取数据操作，所以需要单独处理
取数据的过程（包括关联取数据等），然后才能进行统计和分析。

3. 完成分析逻辑，并且将数据保存成XML格式，因为数据形式比较多样，但是每一种数据的
条数又非常少，所以以XML文件的格式，保存数据比存到数据库要简单高效的多。但是需要
学习python对XML的操作。

4. 对数据进行可视化。以最近流行的数据报告的形式呈现，主要使用H5全屏页面的格式。
最后的时候对整个过程进行完善，添加时间范围为一周，并且每次运行清空部分数据表格。

> 说实话，我觉得这个数据分析交给一个人做可能就需要完整一周的时间，不过现在
也没有什么办法了，硬着头皮上呗。最近还有很多其他的事情也都需要处理，要注意
时间上的协调。



